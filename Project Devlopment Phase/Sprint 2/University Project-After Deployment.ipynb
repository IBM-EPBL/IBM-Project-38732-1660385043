# Loading the dataset
import numpy as np 
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

import os, types
import pandas as pd
from botocore.client import Config
import ibm_boto3

def __iter__(self): return 0

# @hidden_cell
# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.
# You might want to remove those credentials before you share the notebook.
cos_client = ibm_boto3.client(service_name='s3',
    ibm_api_key_id='0SRjsRh6GYg_2xfoit5wds9evFgpoPS-mMrlVZX6A71E',
    ibm_auth_endpoint="https://iam.cloud.ibm.com/oidc/token",
    config=Config(signature_version='oauth'),
    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')

bucket = 'universityadmiteligibilitypredict-donotdelete-pr-khbaqufr55adzg'
object_key = 'Admission_Predict.csv'

body = cos_client.get_object(Bucket=bucket,Key=object_key)['Body']
# add missing __iter__ method, so pandas accepts body as file-like object
if not hasattr(body, "__iter__"): body.__iter__ = types.MethodType( __iter__, body )

df = pd.read_csv(body)
df.head()
df.columns
df.rename(columns = {'Serial No.':'Serial_No','GRE Score':'GRE_Score', 'TOEFL Score':'TOEFL_Score', 'University Rating':'University_Rating','Chance of Admit ':'Chance_of_Admit'}, 
          inplace = True)
df.columns
df.describe()
df.info()
df.drop(["Serial_No"],axis=1)
# Exploratory Data Analysis
plt.scatter(df["CGPA"],df.SOP)
plt.xlabel("CGPA")
plt.ylabel("SOP")
plt.title("SOP Vs CGPA")
plt.show()
df[df.CGPA >= 8.5].plot(kind='scatter', x='GRE_Score', y='TOEFL_Score',color="orange")
plt.xlabel("GRE Score")
plt.ylabel("TOEFL SCORE")
plt.title("CGPA>=8.5")
plt.grid(True)
plt.show()
df["GRE_Score"].plot(kind = 'hist',bins = 200,figsize = (6,6))
plt.title("GRE Score and its frequency")
plt.xlabel("GRE Score")
plt.ylabel("Frequency")
plt.show()
y = np.array([df["TOEFL_Score"].min(),df["TOEFL_Score"].mean(),df["TOEFL_Score"].max()])
x = ["Worst","Average","Best"]
plt.bar(x,y)
plt.title("TOEFL Scores")
plt.xlabel("Level")
plt.ylabel("TOEFL Score")
plt.show()
sns.boxplot(x="University_Rating",y="GRE_Score",data=df)
sns.barplot(x="University_Rating",y="TOEFL_Score",data=df,color="magenta")
df_p=sns.PairGrid(df)
df_p.map(plt.scatter)
plt.figure(figsize=(10, 10))
sns.heatmap(df.corr(), annot=True, linewidths=0.05, fmt= '.2f',cmap="magma")
plt.show()
corr=df.corr()
mask=np.triu(np.ones_like(corr,dtype=bool))
plt.figure(figsize=(10,10))
plt.title("Correlation Matrix")
sns.heatmap(corr,mask=mask,cmap="rocket",linewidths=.5)
plt.show()
var = df[df.columns[1:]].corr()['Chance_of_Admit'][:]
var.sort_values(ascending=False)
sns.barplot(x="University_Rating", y="Chance_of_Admit", hue="Research", data=df)
# Model Building
y = df["Chance_of_Admit"].values
x = df.drop(["Chance_of_Admit"],axis=1)
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.20,random_state=1)
from sklearn.preprocessing import MinMaxScaler
scalerX = MinMaxScaler(feature_range=(0, 1))
x_train[x_train.columns] = scalerX.fit_transform(x_train[x_train.columns])
x_test[x_test.columns] = scalerX.transform(x_test[x_test.columns])
# Training the model using different algorithms
## Linear regression
from sklearn.linear_model import LinearRegression
model = LinearRegression()
model.fit(x_train,y_train)
LinearRegression()
y_predict = model.predict(x_test)
score=model.score(x_test, y_test)
print(score)
print(y_predict[0:5])
print(y_test[0:5])
# Performance metrics
from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error

print('Mean Absolute Error:', mean_absolute_error(y_test, y_predict))  
print('Mean Squared Error:', mean_squared_error(y_test, y_predict))  
print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_predict)))
import pickle
pickle.dump(model,open("model.pkl","wb"))
# Deployment
!pip install -U ibm-watson-machine-learning
from ibm_watson_machine_learning import APIClient
import json
import numpy as np
# Authenticate and Set Space
wml_credentials = {
    "apikey":"Jeb0g58pvgNysUSRkeGY1N2ia4NmTRGIQNZonG46ZMGE",
    "url":"https://us-south.ml.cloud.ibm.com"
}
wml_client = APIClient(wml_credentials)
wml_client.spaces.list()
SPACE_ID = "8b652aee-bdf7-44d5-87b1-16f806de6b5b"
wml_client.set.default_space(SPACE_ID)
wml_client.software_specifications.list()
# Save and deploy the model
import sklearn
sklearn.__version__
MODEL_NAME = "University Admit Eligibility Predictor"
DEPLOYMENT_NAME = "University Admit Eligibility Predictor"
DEMO_MODEL = model
software_spec_uid = wml_client.software_specifications.get_id_by_name('runtime-22.1-py3.9')
model_props = {
    wml_client.repository.ModelMetaNames.NAME: MODEL_NAME,
    wml_client.repository.ModelMetaNames.TYPE: 'scikit-learn_1.0',
    wml_client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: software_spec_uid
}
model_details = wml_client.repository.store_model(
    model = DEMO_MODEL,
    meta_props = model_props,
    training_data = x_train,
    training_target = y_train
)
model_details
model_id = wml_client.repository.get_model_id(model_details)
model_id
deployment_props = {
    wml_client.deployments.ConfigurationMetaNames: DEPLOYMENT_NAME,
    wml_client.deployments.ConfigurationMetaNames.ONLINE: {}
}
deployment = wml_client.deployments.create(
    artifact_uid = model_id,
    meta_props = deployment_props
)
