# Loading the dataset
import numpy as np 
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
df = pd.read_csv("C://Users//Mohana Sowdesh//Desktop//IBM Nalaiya Thiran//Admission_Predict.csv")
df.head()
df.columns
df.rename(columns = {'Serial No.':'Serial_No','GRE Score':'GRE_Score', 'TOEFL Score':'TOEFL_Score', 'University Rating':'University_Rating','Chance of Admit ':'Chance_of_Admit'}, 
          inplace = True)
df.columns
df.describe()
df.info()
df.drop(["Serial_No"],axis=1)
# Exploratory Data Analysis
plt.scatter(df["CGPA"],df.SOP)
plt.xlabel("CGPA")
plt.ylabel("SOP")
plt.title("SOP Vs CGPA")
plt.show()
df[df.CGPA >= 8.5].plot(kind='scatter', x='GRE_Score', y='TOEFL_Score',color="orange")
plt.xlabel("GRE Score")
plt.ylabel("TOEFL SCORE")
plt.title("CGPA>=8.5")
plt.grid(True)
plt.show()
df["GRE_Score"].plot(kind = 'hist',bins = 200,figsize = (6,6))
plt.title("GRE Score and its frequency")
plt.xlabel("GRE Score")
plt.ylabel("Frequency")
plt.show()
y = np.array([df["TOEFL_Score"].min(),df["TOEFL_Score"].mean(),df["TOEFL_Score"].max()])
x = ["Worst","Average","Best"]
plt.bar(x,y)
plt.title("TOEFL Scores")
plt.xlabel("Level")
plt.ylabel("TOEFL Score")
plt.show()
sns.boxplot(x="University_Rating",y="GRE_Score",data=df)
sns.barplot(x="University_Rating",y="TOEFL_Score",data=df,color="magenta")
df_p=sns.PairGrid(df)
df_p.map(plt.scatter)
plt.figure(figsize=(10, 10))
sns.heatmap(df.corr(), annot=True, linewidths=0.05, fmt= '.2f',cmap="magma")
plt.show()
corr=df.corr()
mask=np.triu(np.ones_like(corr,dtype=bool))
plt.figure(figsize=(10,10))
plt.title("Correlation Matrix")
sns.heatmap(corr,mask=mask,cmap="rocket",linewidths=.5)
plt.show()
var = df[df.columns[1:]].corr()['Chance_of_Admit'][:]
var.sort_values(ascending=False)
sns.barplot(x="University_Rating", y="Chance_of_Admit", hue="Research", data=df)
# Model Building
y = df["Chance_of_Admit"].values
x = df.drop(["Chance_of_Admit"],axis=1)
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.20,random_state=1)
from sklearn.preprocessing import MinMaxScaler
scalerX = MinMaxScaler(feature_range=(0, 1))
x_train[x_train.columns] = scalerX.fit_transform(x_train[x_train.columns])
x_test[x_test.columns] = scalerX.transform(x_test[x_test.columns])
# Training the model using different algorithms
## Linear regression
from sklearn.linear_model import LinearRegression
model = LinearRegression()
model.fit(x_train,y_train)
LinearRegression()
y_predict = model.predict(x_test)
score=model.score(x_test, y_test)
print(score)
print(y_predict[0:5])
print(y_test[0:5])
# Performance metrics
from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error

print('Mean Absolute Error:', mean_absolute_error(y_test, y_predict))  
print('Mean Squared Error:', mean_squared_error(y_test, y_predict))  
print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_predict)))
import pickle
pickle.dump(model,open("model.pkl","wb"))